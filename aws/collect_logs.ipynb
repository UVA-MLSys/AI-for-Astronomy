{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T22:22:25.183574Z",
     "start_time": "2025-10-21T22:22:25.177539Z"
    }
   },
   "source": [
    "import boto3, re, json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import pytz"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T22:22:26.875554Z",
     "start_time": "2025-10-21T22:22:26.872554Z"
    }
   },
   "source": [
    "result_path_pattern = re.compile(r\"result-partition-(?P<partition>[0-9]+MB)/(?P<data_size>[0-9]+GB)/(run )?(?P<run_no>[0-9]+)\")\n",
    "search_result = result_path_pattern.search(\"result-partition-75MB/1GB/1\")\n",
    "search_dict = search_result.groupdict()"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T22:22:28.361746Z",
     "start_time": "2025-10-21T22:22:28.358769Z"
    }
   },
   "source": [
    "pattern = re.compile(r\"result-partition-[0-9]+MB/((total)|([0-9]+GB))/(run )?[0-9]+\")"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T22:22:32.232718Z",
     "start_time": "2025-10-21T22:22:32.213274Z"
    }
   },
   "source": "def get_event_details(event):\n    return event.get('executionSucceededEventDetails') or \\\n        event.get('executionFailedEventDetails') or \\\n        event.get('executionStartedEventDetails') or \\\n        event.get('stateEnteredEventDetails') or {}\n\ndef extract_event_details(history, results, verbose):\n    state = 0\n    execution_start, execution_end = None, None\n    inference_start, inference_end = None, None\n    result_path = None\n\n    # Print execution events\n    for event in history['events']:\n        timestamp = event['timestamp']\n        event_type = event['type']\n        details = get_event_details(event)\n        \n        if verbose:print(f\"{timestamp} - {event_type}\")\n        if details is not None and verbose:\n            print(f\"  Details: {details}\")\n            \n        try:\n            if event_type == 'ExecutionStarted': \n                execution_start = timestamp\n            elif event_type == 'ExecutionSucceeded': execution_end = timestamp\n            elif event_type == 'TaskStateEntered': \n                if state ==0:\n                    input_json = json.loads(details['input'])\n                    result_path = input_json['result_path']\n                    # print(f\"{timestamp}: Result Path: {result_path}\")\n                \n                    # if pattern.fullmatch(result_path) is None:\n                    if \"demo\" in result_path or result_path in results['result_path']:\n                        # print(f\"Skipping {result_path}.\")\n                        return results\n                    \n                    result_path_splitted = result_path.split('/')\n                    # \"result-partition-100MB/1GB/1\" or \"result-partition-100MB/1GB/run 1\"\n                    \n                    if 'Batches' in result_path:\n                        data_size = result_path_splitted[-4]\n                    else:\n                        data_size = result_path_splitted[-2]\n                    if data_size == 'total': data_size = '12.6GB'\n                    \n                    run_no = result_path_splitted[-1].replace('run ', '')\n                    partition_size = input_json['data_prefix']\n                    batch_size = input_json['batch_size']\n                \n                state += 1\n            elif event_type == 'MapStateEntered':\n                # input_json = json.loads(details['input'])\n                 \n                inference_start = timestamp\n                state += 1\n            elif event_type == 'MapStateExited': \n                inference_end = timestamp\n                state += 1\n                \n        except Exception as e:\n            print(f\"  Error {e.with_traceback}\")\n            return results\n            \n    if verbose: print(\"-\" * 80)\n    \n    delta = (execution_end - execution_start)\n    total_duration = delta.seconds +  delta.microseconds / 1e6 # convert to seconds\n    if verbose: print(f\"Total Duration: {total_duration:.2f} seconds.\")\n\n    delta = (inference_end - inference_start)\n    inference_duration = delta.seconds +  delta.microseconds / 1e6 # convert to seconds\n    if verbose: print(f\"Inference Duration: {inference_duration:.2f} seconds.\")\n\n    results['result_path'].append(result_path)\n    results['data (GB)'].append(data_size)\n    results['run'].append(run_no)\n    results['partition (MB)'].append(partition_size)\n    results['total_duration (s)'].append(total_duration)\n    results['inference_duration (s)'].append(inference_duration)\n    results['batch_size'].append(batch_size)\n    results['batch_varying'].append('Batches' in result_path)\n    \n    return results\n\ndef get_step_function_logs(\n    state_machine_arn, start_date=None, end_date=None,\n    verbose=False, profile_name=None\n):\n    \"\"\"\n    Collects the events log for a specific AWS Step Functions state machine.\n\n    :param state_machine_arn: The ARN of the Step Functions state machine\n    :param start_date: Optional, filter logs starting from this date (timezone-aware datetime object)\n    :param end_date: Optional, filter logs until this date (timezone-aware datetime object)\n    :param profile_name: Optional, AWS profile name to use\n    \"\"\"\n    # Initialize boto3 session with profile if provided\n    if profile_name:\n        session = boto3.Session(profile_name=profile_name)\n        stepfunctions_client = session.client('stepfunctions', region_name='us-east-1')\n    else:\n        stepfunctions_client = boto3.client('stepfunctions', region_name='us-east-1')\n        \n    results = {\n        key: [] for key in [\n            'result_path', 'data (GB)','batch_size', 'run', \n            'partition (MB)', 'total_duration (s)', \n            'inference_duration (s)', 'batch_varying']\n    }\n\n    try:\n        # List executions for the state machine\n        executions = stepfunctions_client.list_executions(\n            stateMachineArn=state_machine_arn,\n            statusFilter='SUCCEEDED',  # You can filter by RUNNING, FAILED, etc.\n            maxResults=1000 # update if you have more than 1000 executions\n        )\n\n        print(f\"Fetching logs for Step Functions state machine: {state_machine_arn}\\n\")\n        print(f\"Found {len(executions['executions'])} executions.\\n\")\n\n        # Iterate through executions\n        for execution in executions['executions']:\n            execution_arn = execution['executionArn']\n            start_time = execution['startDate']\n            stop_time = execution['stopDate']\n            \n            # Ensure start_date and end_date are timezone-aware and in UTC\n            if start_date:\n                start_date = start_date.astimezone(pytz.utc)\n            if end_date:\n                end_date = end_date.astimezone(pytz.utc)\n\n            # Filter by start_date and end_date if provided\n            if start_date and start_time < start_date:\n                continue\n            if end_date and stop_time > end_date:\n                continue\n            \n            if verbose: print(f\"Execution ARN: {execution_arn}\")\n            if verbose: print(f\"Start Time: {start_time}, Stop Time: {stop_time}\")\n\n            # Get execution history\n            history = stepfunctions_client.get_execution_history(\n                executionArn=execution_arn,\n                reverseOrder=False  # Set to True if you want events in reverse order\n            )\n            \n            results = extract_event_details(history, results, verbose)\n            # break\n            \n    except stepfunctions_client.exceptions.ResourceNotFound:\n        print(f\"The state machine ARN {state_machine_arn} does not exist.\")\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n        \n    del results['result_path']\n    return results",
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T22:22:50.222574Z",
     "start_time": "2025-10-21T22:22:39.947198Z"
    }
   },
   "source": [
    "state_machine_arn = \"arn:aws:states:us-east-1:448324707516:stateMachine:DataParallel-CosmicAI\"\n",
    "\n",
    "# Optional: Define a time range (use timezone-aware UTC datetimes)\n",
    "start_date = datetime(2024, 11, 11, 0, 0, 0, tzinfo=pytz.utc)  # Example: Start from this date\n",
    "end_date = None # datetime(2024, 11, 22, 23, 0, 0, tzinfo=pytz.utc)    # Example: Until this date\n",
    "\n",
    "results = get_step_function_logs(state_machine_arn, start_date, end_date, profile_name= \"cylon\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching logs for Step Functions state machine: arn:aws:states:us-east-1:448324707516:stateMachine:DataParallel-CosmicAI\n",
      "\n",
      "Found 53 executions.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T22:22:51.624243Z",
     "start_time": "2025-10-21T22:22:51.608028Z"
    }
   },
   "source": [
    "df = pd.DataFrame(results)\n",
    "df = df[(df['data (GB)'] != '100MB') & (df['partition (MB)'] != 'data')]\n",
    "# because the first ones are latest\n",
    "df.drop_duplicates(subset=['data (GB)', 'batch_size', 'run', 'partition (MB)', 'batch_varying'], inplace=True, keep='first')\n",
    "df.head(30)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   data (GB)  batch_size run partition (MB)  total_duration (s)  \\\n",
       "0     timing         512   3          100MB              74.755   \n",
       "1     timing         512   1          100MB              77.395   \n",
       "2     timing         512   2          100MB              63.122   \n",
       "3       test         512   1          100MB              74.800   \n",
       "4      768GB         512   5          100MB             188.916   \n",
       "5      768GB         512   4          100MB             219.121   \n",
       "6      768GB         512   3          100MB             194.173   \n",
       "7      768GB         512   2          100MB             194.479   \n",
       "8      768GB         512   1          100MB             184.637   \n",
       "9      512GB         512   3          100MB             226.658   \n",
       "10     512GB         512   2          100MB             159.606   \n",
       "11     512GB         512   1          100MB             168.030   \n",
       "12     256GB         512   3          100MB             124.557   \n",
       "13     256GB         512   2          100MB             144.661   \n",
       "14     256GB         512   1          100MB             136.589   \n",
       "15     983GB         512   3          100MB             109.010   \n",
       "16     983GB         512   2          100MB             109.204   \n",
       "17     983GB         512   1          100MB             116.807   \n",
       "18       1TB         512   3          100MB             220.969   \n",
       "19       1TB         512   2          100MB             242.601   \n",
       "20       1TB         512   1          100MB             246.868   \n",
       "21     100GB         512   3          100MB              73.525   \n",
       "23     100GB         512   2          100MB              58.088   \n",
       "24     100GB         512   1          100MB              59.686   \n",
       "26       2GB         512   1           50MB              58.628   \n",
       "\n",
       "    inference_duration (s)  batch_varying  \n",
       "0                   63.972          False  \n",
       "1                   68.982          False  \n",
       "2                   58.467          False  \n",
       "3                   62.448          False  \n",
       "4                  133.391          False  \n",
       "5                  165.565          False  \n",
       "6                  144.728          False  \n",
       "7                  139.633          False  \n",
       "8                  131.597          False  \n",
       "9                  171.852          False  \n",
       "10                 106.549          False  \n",
       "11                 112.270          False  \n",
       "12                  71.847          False  \n",
       "13                  93.242          False  \n",
       "14                  81.686          False  \n",
       "15                  58.997          False  \n",
       "16                  58.983          False  \n",
       "17                  65.134          False  \n",
       "18                 163.889          False  \n",
       "19                 184.574          False  \n",
       "20                 193.245          False  \n",
       "21                  63.339          False  \n",
       "23                  51.262          False  \n",
       "24                  52.764          False  \n",
       "26                  50.799          False  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data (GB)</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>run</th>\n",
       "      <th>partition (MB)</th>\n",
       "      <th>total_duration (s)</th>\n",
       "      <th>inference_duration (s)</th>\n",
       "      <th>batch_varying</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>timing</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>100MB</td>\n",
       "      <td>74.755</td>\n",
       "      <td>63.972</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>timing</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>100MB</td>\n",
       "      <td>77.395</td>\n",
       "      <td>68.982</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>timing</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>100MB</td>\n",
       "      <td>63.122</td>\n",
       "      <td>58.467</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>100MB</td>\n",
       "      <td>74.800</td>\n",
       "      <td>62.448</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>768GB</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>100MB</td>\n",
       "      <td>188.916</td>\n",
       "      <td>133.391</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>768GB</td>\n",
       "      <td>512</td>\n",
       "      <td>4</td>\n",
       "      <td>100MB</td>\n",
       "      <td>219.121</td>\n",
       "      <td>165.565</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>768GB</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>100MB</td>\n",
       "      <td>194.173</td>\n",
       "      <td>144.728</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>768GB</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>100MB</td>\n",
       "      <td>194.479</td>\n",
       "      <td>139.633</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>768GB</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>100MB</td>\n",
       "      <td>184.637</td>\n",
       "      <td>131.597</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>512GB</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>100MB</td>\n",
       "      <td>226.658</td>\n",
       "      <td>171.852</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>512GB</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>100MB</td>\n",
       "      <td>159.606</td>\n",
       "      <td>106.549</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>512GB</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>100MB</td>\n",
       "      <td>168.030</td>\n",
       "      <td>112.270</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>256GB</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>100MB</td>\n",
       "      <td>124.557</td>\n",
       "      <td>71.847</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>256GB</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>100MB</td>\n",
       "      <td>144.661</td>\n",
       "      <td>93.242</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>256GB</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>100MB</td>\n",
       "      <td>136.589</td>\n",
       "      <td>81.686</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>983GB</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>100MB</td>\n",
       "      <td>109.010</td>\n",
       "      <td>58.997</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>983GB</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>100MB</td>\n",
       "      <td>109.204</td>\n",
       "      <td>58.983</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>983GB</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>100MB</td>\n",
       "      <td>116.807</td>\n",
       "      <td>65.134</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1TB</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>100MB</td>\n",
       "      <td>220.969</td>\n",
       "      <td>163.889</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1TB</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>100MB</td>\n",
       "      <td>242.601</td>\n",
       "      <td>184.574</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1TB</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>100MB</td>\n",
       "      <td>246.868</td>\n",
       "      <td>193.245</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100GB</td>\n",
       "      <td>512</td>\n",
       "      <td>3</td>\n",
       "      <td>100MB</td>\n",
       "      <td>73.525</td>\n",
       "      <td>63.339</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100GB</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>100MB</td>\n",
       "      <td>58.088</td>\n",
       "      <td>51.262</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>100GB</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>100MB</td>\n",
       "      <td>59.686</td>\n",
       "      <td>52.764</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2GB</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>50MB</td>\n",
       "      <td>58.628</td>\n",
       "      <td>50.799</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T22:23:00.700932Z",
     "start_time": "2025-10-21T22:23:00.641742Z"
    }
   },
   "source": "# Convert TB to GB first, then remove units and convert to float\ndf['data (GB)'] = df['data (GB)'].str.replace('TB', '000').str.replace('GB', '').astype(float)\ndf['partition (MB)'] = df['partition (MB)'].str.replace('MB', '').astype(int)\ndf['num_worlds'] = ((df['data (GB)'] * 1024 + df['partition (MB)'] -1 ) // df['partition (MB)']).astype(int)",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'timing'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Convert TB to GB first, then remove units and convert to float\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata (GB)\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdata (GB)\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreplace\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mTB\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m000\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreplace\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mGB\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mfloat\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpartition (MB)\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpartition (MB)\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mstr\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMB\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mint\u001B[39m)\n\u001B[1;32m      4\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnum_worlds\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m ((df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata (GB)\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m1024\u001B[39m \u001B[38;5;241m+\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpartition (MB)\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m ) \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpartition (MB)\u001B[39m\u001B[38;5;124m'\u001B[39m])\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mint\u001B[39m)\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/generic.py:6240\u001B[0m, in \u001B[0;36mNDFrame.astype\u001B[0;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[1;32m   6233\u001B[0m     results \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m   6234\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miloc[:, i]\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n\u001B[1;32m   6235\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns))\n\u001B[1;32m   6236\u001B[0m     ]\n\u001B[1;32m   6238\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   6239\u001B[0m     \u001B[38;5;66;03m# else, only a single dtype is given\u001B[39;00m\n\u001B[0;32m-> 6240\u001B[0m     new_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mgr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   6241\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_constructor(new_data)\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mastype\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   6243\u001B[0m \u001B[38;5;66;03m# GH 33113: handle empty frame or series\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/internals/managers.py:448\u001B[0m, in \u001B[0;36mBaseBlockManager.astype\u001B[0;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[1;32m    447\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mastype\u001B[39m(\u001B[38;5;28mself\u001B[39m: T, dtype, copy: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m, errors: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m T:\n\u001B[0;32m--> 448\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mastype\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/internals/managers.py:352\u001B[0m, in \u001B[0;36mBaseBlockManager.apply\u001B[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001B[0m\n\u001B[1;32m    350\u001B[0m         applied \u001B[38;5;241m=\u001B[39m b\u001B[38;5;241m.\u001B[39mapply(f, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    351\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 352\u001B[0m         applied \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    353\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mNotImplementedError\u001B[39;00m):\n\u001B[1;32m    354\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ignore_failures:\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/internals/blocks.py:526\u001B[0m, in \u001B[0;36mBlock.astype\u001B[0;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[1;32m    508\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    509\u001B[0m \u001B[38;5;124;03mCoerce to the new dtype.\u001B[39;00m\n\u001B[1;32m    510\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    522\u001B[0m \u001B[38;5;124;03mBlock\u001B[39;00m\n\u001B[1;32m    523\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    524\u001B[0m values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalues\n\u001B[0;32m--> 526\u001B[0m new_values \u001B[38;5;241m=\u001B[39m \u001B[43mastype_array_safe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    528\u001B[0m new_values \u001B[38;5;241m=\u001B[39m maybe_coerce_values(new_values)\n\u001B[1;32m    529\u001B[0m newb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmake_block(new_values)\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/dtypes/astype.py:299\u001B[0m, in \u001B[0;36mastype_array_safe\u001B[0;34m(values, dtype, copy, errors)\u001B[0m\n\u001B[1;32m    296\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m values\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m    298\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 299\u001B[0m     new_values \u001B[38;5;241m=\u001B[39m \u001B[43mastype_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    300\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mValueError\u001B[39;00m, \u001B[38;5;167;01mTypeError\u001B[39;00m):\n\u001B[1;32m    301\u001B[0m     \u001B[38;5;66;03m# e.g. astype_nansafe can fail on object-dtype of strings\u001B[39;00m\n\u001B[1;32m    302\u001B[0m     \u001B[38;5;66;03m#  trying to convert to float\u001B[39;00m\n\u001B[1;32m    303\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/dtypes/astype.py:230\u001B[0m, in \u001B[0;36mastype_array\u001B[0;34m(values, dtype, copy)\u001B[0m\n\u001B[1;32m    227\u001B[0m     values \u001B[38;5;241m=\u001B[39m values\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n\u001B[1;32m    229\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 230\u001B[0m     values \u001B[38;5;241m=\u001B[39m \u001B[43mastype_nansafe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    232\u001B[0m \u001B[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001B[39;00m\n\u001B[1;32m    233\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(dtype, np\u001B[38;5;241m.\u001B[39mdtype) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(values\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mtype, \u001B[38;5;28mstr\u001B[39m):\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/dtypes/astype.py:170\u001B[0m, in \u001B[0;36mastype_nansafe\u001B[0;34m(arr, dtype, copy, skipna)\u001B[0m\n\u001B[1;32m    166\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[1;32m    168\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copy \u001B[38;5;129;01mor\u001B[39;00m is_object_dtype(arr\u001B[38;5;241m.\u001B[39mdtype) \u001B[38;5;129;01mor\u001B[39;00m is_object_dtype(dtype):\n\u001B[1;32m    169\u001B[0m     \u001B[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001B[39;00m\n\u001B[0;32m--> 170\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43marr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    172\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n",
      "\u001B[0;31mValueError\u001B[0m: could not convert string to float: 'timing'"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T18:21:28.022741Z",
     "start_time": "2025-10-21T18:21:27.559465Z"
    }
   },
   "source": [
    "df = df[['partition (MB)', 'data (GB)', 'batch_size', 'batch_varying', 'run', 'num_worlds', 'total_duration (s)', 'inference_duration (s)']]\n",
    "df.sort_values(by=['partition (MB)', 'data (GB)','batch_size','batch_varying', 'run'], inplace=True)"
   ],
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['num_worlds'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpartition (MB)\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdata (GB)\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbatch_size\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mbatch_varying\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrun\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mnum_worlds\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtotal_duration (s)\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43minference_duration (s)\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m      2\u001B[0m df\u001B[38;5;241m.\u001B[39msort_values(by\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpartition (MB)\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata (GB)\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbatch_size\u001B[39m\u001B[38;5;124m'\u001B[39m,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbatch_varying\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrun\u001B[39m\u001B[38;5;124m'\u001B[39m], inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/frame.py:3813\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3811\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_iterator(key):\n\u001B[1;32m   3812\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[0;32m-> 3813\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_indexer_strict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcolumns\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m   3815\u001B[0m \u001B[38;5;66;03m# take() does not accept boolean indexers\u001B[39;00m\n\u001B[1;32m   3816\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(indexer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/indexes/base.py:6070\u001B[0m, in \u001B[0;36mIndex._get_indexer_strict\u001B[0;34m(self, key, axis_name)\u001B[0m\n\u001B[1;32m   6067\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   6068\u001B[0m     keyarr, indexer, new_indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reindex_non_unique(keyarr)\n\u001B[0;32m-> 6070\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_if_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   6072\u001B[0m keyarr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtake(indexer)\n\u001B[1;32m   6073\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Index):\n\u001B[1;32m   6074\u001B[0m     \u001B[38;5;66;03m# GH 42790 - Preserve name from an Index\u001B[39;00m\n",
      "File \u001B[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/indexes/base.py:6133\u001B[0m, in \u001B[0;36mIndex._raise_if_missing\u001B[0;34m(self, key, indexer, axis_name)\u001B[0m\n\u001B[1;32m   6130\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   6132\u001B[0m not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39munique())\n\u001B[0;32m-> 6133\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mKeyError\u001B[0m: \"['num_worlds'] not in index\""
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T22:23:28.576898Z",
     "start_time": "2025-10-21T22:23:28.571446Z"
    }
   },
   "source": [
    "df.round(2).to_csv('./results/state_machine_logs.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
